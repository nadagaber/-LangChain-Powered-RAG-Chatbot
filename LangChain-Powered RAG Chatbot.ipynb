{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-07T12:18:55.664672Z",
          "iopub.status.busy": "2025-05-07T12:18:55.663989Z",
          "iopub.status.idle": "2025-05-07T12:19:40.362512Z",
          "shell.execute_reply": "2025-05-07T12:19:40.361552Z",
          "shell.execute_reply.started": "2025-05-07T12:18:55.664646Z"
        },
        "id": "_bGWbVRoqNme",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!sudo apt install pciutils lshw\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "!pip install -U langchain-ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-07T12:19:40.364165Z",
          "iopub.status.busy": "2025-05-07T12:19:40.363865Z",
          "iopub.status.idle": "2025-05-07T12:19:43.592941Z",
          "shell.execute_reply": "2025-05-07T12:19:43.592115Z",
          "shell.execute_reply.started": "2025-05-07T12:19:40.364141Z"
        },
        "id": "tvVn0DGyqBWc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-07T12:19:47.002160Z",
          "iopub.status.busy": "2025-05-07T12:19:47.001897Z",
          "iopub.status.idle": "2025-05-07T12:19:52.007105Z",
          "shell.execute_reply": "2025-05-07T12:19:52.006551Z",
          "shell.execute_reply.started": "2025-05-07T12:19:47.002137Z"
        },
        "id": "W0js0KNKqoqn",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "def run_ollama_serve():\n",
        "    subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "thread = threading.Thread(target=run_ollama_serve)\n",
        "thread.start()\n",
        "time.sleep(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-05-07T12:19:52.007934Z",
          "iopub.status.busy": "2025-05-07T12:19:52.007768Z",
          "iopub.status.idle": "2025-05-07T12:19:52.145290Z",
          "shell.execute_reply": "2025-05-07T12:19:52.144592Z",
          "shell.execute_reply.started": "2025-05-07T12:19:52.007920Z"
        },
        "id": "p6T_3589qszC",
        "outputId": "1aba9745-7de5-45ee-91aa-df2b86de63c1",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ollama version is 0.6.8\n"
          ]
        }
      ],
      "source": [
        "!ollama --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-05-07T12:19:52.146606Z",
          "iopub.status.busy": "2025-05-07T12:19:52.146310Z",
          "iopub.status.idle": "2025-05-07T12:19:52.748232Z",
          "shell.execute_reply": "2025-05-07T12:19:52.747602Z",
          "shell.execute_reply.started": "2025-05-07T12:19:52.146581Z"
        },
        "id": "abDW5hPurK1Y",
        "outputId": "589295a8-2fd9-4a83-e26b-d112a09fd695",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
            "pulling 970aa74c0a90: 100% ▕▏ 274 MB                         \u001b[K\n",
            "pulling c71d239df917: 100% ▕▏  11 KB                         \u001b[K\n",
            "pulling ce4a164fc046: 100% ▕▏   17 B                         \u001b[K\n",
            "pulling 31df23ea7daa: 100% ▕▏  420 B                         \u001b[K\n",
            "verifying sha256 digest \u001b[K\n",
            "writing manifest \u001b[K\n",
            "success \u001b[K\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ],
      "source": [
        "!ollama pull nomic-embed-text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-05-07T12:19:52.749352Z",
          "iopub.status.busy": "2025-05-07T12:19:52.749123Z",
          "iopub.status.idle": "2025-05-07T12:19:53.332717Z",
          "shell.execute_reply": "2025-05-07T12:19:53.331973Z",
          "shell.execute_reply.started": "2025-05-07T12:19:52.749305Z"
        },
        "id": "lEz66mFqrNN-",
        "outputId": "914d5076-3b73-4fe3-feed-eafaa46aaa16",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
            "pulling 6a0746a1ec1a: 100% ▕▏ 4.7 GB                         \u001b[K\n",
            "pulling 4fa551d4f938: 100% ▕▏  12 KB                         \u001b[K\n",
            "pulling 8ab4849b038c: 100% ▕▏  254 B                         \u001b[K\n",
            "pulling 577073ffcc6c: 100% ▕▏  110 B                         \u001b[K\n",
            "pulling 3f8eb4da87fa: 100% ▕▏  485 B                         \u001b[K\n",
            "verifying sha256 digest \u001b[K\n",
            "writing manifest \u001b[K\n",
            "success \u001b[K\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ],
      "source": [
        "!ollama pull llama3.1:8b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-05-07T12:19:53.333799Z",
          "iopub.status.busy": "2025-05-07T12:19:53.333600Z",
          "iopub.status.idle": "2025-05-07T12:19:56.367351Z",
          "shell.execute_reply": "2025-05-07T12:19:56.366395Z",
          "shell.execute_reply.started": "2025-05-07T12:19:53.333777Z"
        },
        "id": "fVQxwVYkyg9s",
        "outputId": "2aa73ab8-0aea-40d1-db87-bd935938914c",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ],
      "source": [
        "pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-07T12:19:56.368851Z",
          "iopub.status.busy": "2025-05-07T12:19:56.368545Z",
          "iopub.status.idle": "2025-05-07T12:19:59.510732Z",
          "shell.execute_reply": "2025-05-07T12:19:59.509843Z",
          "shell.execute_reply.started": "2025-05-07T12:19:56.368816Z"
        },
        "id": "X1k0Oi6tyg9t",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "pip install langchain_experimental"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-05-07T12:19:59.513107Z",
          "iopub.status.busy": "2025-05-07T12:19:59.512855Z",
          "iopub.status.idle": "2025-05-07T12:20:03.043368Z",
          "shell.execute_reply": "2025-05-07T12:20:03.042606Z",
          "shell.execute_reply.started": "2025-05-07T12:19:59.513075Z"
        },
        "id": "dKPwtcm3yg9t",
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-05-07T12:23:26.523719Z",
          "iopub.status.busy": "2025-05-07T12:23:26.523168Z",
          "iopub.status.idle": "2025-05-07T12:23:31.443038Z",
          "shell.execute_reply": "2025-05-07T12:23:31.442158Z",
          "shell.execute_reply.started": "2025-05-07T12:23:26.523696Z"
        },
        "id": "xkHl2O32yg9u",
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "pip install google-search-results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-07T12:32:08.399769Z",
          "iopub.status.busy": "2025-05-07T12:32:08.399027Z",
          "iopub.status.idle": "2025-05-07T12:32:08.405706Z",
          "shell.execute_reply": "2025-05-07T12:32:08.404735Z",
          "shell.execute_reply.started": "2025-05-07T12:32:08.399742Z"
        },
        "id": "E3gjdoodyg9u",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain_ollama import OllamaEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_ollama import ChatOllama\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain_experimental.tools import PythonREPLTool\n",
        "from langchain_community.utilities import SerpAPIWrapper\n",
        "from langchain.agents import Tool\n",
        "from langchain_experimental.tools import PythonREPLTool\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-07T12:22:23.641588Z",
          "iopub.status.busy": "2025-05-07T12:22:23.640936Z",
          "iopub.status.idle": "2025-05-07T12:22:23.645036Z",
          "shell.execute_reply": "2025-05-07T12:22:23.644362Z",
          "shell.execute_reply.started": "2025-05-07T12:22:23.641564Z"
        },
        "id": "24zaHG8Ryg9u",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "os.environ[\"SERPAPI_API_KEY\"] = \"SERPAPIKEY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jjURZggD2yGf"
      },
      "outputs": [],
      "source": [
        "# --- Step 1: Load text documents ---\n",
        "file = 'merged_langchain_docs.txt'\n",
        "documents = []\n",
        "\n",
        "loader = TextLoader(file)\n",
        "documents.extend(loader.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4dyCgR7w23B8"
      },
      "outputs": [],
      "source": [
        "# --- Step 2: Chunk documents for better embedding ---\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "split_docs = splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qE_S3m33248-"
      },
      "outputs": [],
      "source": [
        "# --- Step 3: Create embeddings and FAISS vector DB ---\n",
        "embedding_model = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
        "vectordb = FAISS.from_documents(split_docs, embedding_model)\n",
        "vectordb.save_local(\"faiss_index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "txIrD2No2875"
      },
      "outputs": [],
      "source": [
        "# --- Step 4: Set up tools ---\n",
        "retriever_tool = vectordb.as_retriever(search_type=\"similarity\", k=3)\n",
        "\n",
        "langchain_doc_tool = Tool(\n",
        "    name=\"LangChainDocs\",\n",
        "    func=retriever_tool.get_relevant_documents,\n",
        "    description=\"Useful for answering any question about LangChain, e.g, its features, usage, components, and examples.\"\n",
        ")\n",
        "\n",
        "search = SerpAPIWrapper()\n",
        "search_tool = Tool(\n",
        "    name=\"Search\",\n",
        "    func=search.run,\n",
        "    description=\"Useful for answering questions (not about LangChain) about current events or general knowledge from the web.\"\n",
        ")\n",
        "\n",
        "python_tool = PythonREPLTool()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bN-nIuTh2-4C"
      },
      "outputs": [],
      "source": [
        "# --- Step 5: Load LLM ---\n",
        "llm = ChatOllama(model=\"llama3.1:8b\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dayhbubo3Bjj",
        "outputId": "fde2651a-2219-4a7e-9d34-930c96a2b842"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-916320d495e8>:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
          ]
        }
      ],
      "source": [
        "# --- Step 6: Memory for chat history ---\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-05-07T12:32:39.546356Z",
          "iopub.status.busy": "2025-05-07T12:32:39.545831Z",
          "iopub.status.idle": "2025-05-07T12:33:22.553586Z",
          "shell.execute_reply": "2025-05-07T12:33:22.552990Z",
          "shell.execute_reply.started": "2025-05-07T12:32:39.546306Z"
        },
        "id": "2gLRl591n3lw",
        "outputId": "ad803d3b-4bfe-4267-92ad-2863e4141d44",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-19-a6dc22fdfe94>:3: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  agent = initialize_agent(\n"
          ]
        }
      ],
      "source": [
        "# --- Step 7: Initialize agent with tools ---\n",
        "tools = [search_tool, python_tool, langchain_doc_tool]\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "    memory=memory,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TMXo_iv0ruoQ",
        "outputId": "ae653753-f785-4276-e1b5-8c9bee9bf509",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: what are langchain features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-17268432387c>:5: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = agent.run(query)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m```json\n",
            "{\n",
            "    \"action\": \"LangChainDocs\",\n",
            "    \"action_input\": \"\"\n",
            "}\n",
            "```\n",
            "\n",
            "(Note: I've responded in Option 1 format, as the user's input is about LangChain, so it's best to use the `LangChainDocs` tool for this question.)\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3m[Document(id='72503380-5ff5-47bc-8f12-a9f5ebe56b34', metadata={'source': 'merged_langchain_docs.txt'}, page_content='}'), Document(id='49a56077-de3a-46d4-a719-d6d6fb964389', metadata={'source': 'merged_langchain_docs.txt'}, page_content='----'), Document(id='7f5fe472-ce67-4d44-9941-e7d0fdd6482b', metadata={'source': 'merged_langchain_docs.txt'}, page_content='----'), Document(id='4a7570c8-04c1-444a-ab9c-4f5eef3aaee5', metadata={'source': 'merged_langchain_docs.txt'}, page_content='Explanation:\\n\\u200b')]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m```json\n",
            "{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": \"LangChain features include its ability to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\"\n",
            "}\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Bot: LangChain features include its ability to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "You: who is donald trump\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mHere is my response:\n",
            "\n",
            "```json\n",
            "{\n",
            "  \"action\": \"Search\",\n",
            "  \"action_input\": \"Donald Trump\"\n",
            "}\n",
            "```\n",
            "\n",
            "This suggests that the user use the Search tool to look up information about Donald Trump.\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[{'title': \"Trump administration poised to accept 'palace in the sky' as a gift for Trump from Qatar: Sources\", 'link': 'https://abcnews.go.com/Politics/trump-administration-poised-accept-palace-sky-gift-trump/story?id=121680511', 'source': 'ABC News', 'source_logo': 'https://serpapi.com/searches/6820fee43f79e867fb496c63/images/fe3a663b587236fa6154db324addddf3e062152864cdb32cbabe661ec26a43ee.png', 'date': '9 hours ago', 'thumbnail': 'https://serpapi.com/searches/6820fee43f79e867fb496c63/images/fe3a663b587236faf427bd58cb63a037edb5421355dc2a62.jpeg', 'label': 'Highly Cited'}, {'title': 'Trump administration will accept a luxury jet from Qatar to use as Air Force One', 'link': 'https://www.nbcnews.com/politics/donald-trump/trump-administration-will-accept-luxury-jet-qatar-use-air-force-one-rcna206111', 'source': 'NBC News', 'source_logo': 'https://serpapi.com/searches/6820fee43f79e867fb496c63/images/fe3a663b587236fab03f039be17142f165741d85630c2bd8b4c48c9536259015.png', 'date': '3 hours ago', 'thumbnail': 'https://serpapi.com/searches/6820fee43f79e867fb496c63/images/fe3a663b587236fab8712f33c32dff7bb8b01723c0a57d71.jpeg'}, {'title': 'Trump to receive luxury jet for Air Force One from Qatar', 'link': 'https://www.bbc.com/news/articles/cy5ell3gkxvo', 'source': 'BBC', 'source_logo': 'https://serpapi.com/searches/6820fee43f79e867fb496c63/images/fe3a663b587236fa0bdce7f323945b031d799d9845e75a7da78159ef3c22d7fe.png', 'date': '1 hour ago', 'thumbnail': 'https://serpapi.com/searches/6820fee43f79e867fb496c63/images/fe3a663b587236fae5cb1252d16f277c6a045c4e8ae13ff6.jpeg'}, {'title': 'Trump’s presidency: US officials tout progress in China trade talks', 'link': 'https://www.cnn.com/politics/live-news/trump-presidency-news-05-11-25', 'source': 'CNN', 'source_logo': 'https://serpapi.com/searches/6820fee43f79e867fb496c63/images/fe3a663b587236fa88dc0f8e67daf71e25caa2f4c3df46645c2e4b9bd4b1c618.png', 'date': '37 minutes ago', 'thumbnail': 'https://serpapi.com/searches/6820fee43f79e867fb496c63/images/fe3a663b587236fac0a65e8671c1fb52abad347af64f96ae.jpeg', 'live': True}, {'title': 'British ambassador on trade deal: ‘We regard it as finalized’', 'link': 'https://www.politico.com/news/2025/05/11/british-ambassador-trade-deal-finalized-00340922', 'source': 'Politico', 'source_logo': 'https://serpapi.com/searches/6820fee43f79e867fb496c63/images/fe3a663b587236fae28c9e320999c9add3655a7ff1707677dc442f066956b86d.png', 'date': '48 minutes ago', 'thumbnail': 'https://serpapi.com/searches/6820fee43f79e867fb496c63/images/fe3a663b587236fa740b556651693030df18b138e00600a9.jpeg'}]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mHere is my response:\n",
            "\n",
            "```json\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"Donald Trump is an American businessman and politician who served as the 45th President of the United States from 2017 to 2021. He was born on June 14, 1946, in Queens, New York. Trump's presidency was marked by controversy and division, with many criticizing his policies and behavior.\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Bot: Donald Trump is an American businessman and politician who served as the 45th President of the United States from 2017 to 2021. He was born on June 14, 1946, in Queens, New York. Trump's presidency was marked by controversy and division, with many criticizing his policies and behavior.\n",
            "You: how old is he\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m```json\n",
            "{\n",
            "  \"action\": \"Search\",\n",
            "  \"action_input\": \"Donald Trump's birthdate\"\n",
            "}\n",
            "```\n",
            "\n",
            "(Note: I'm suggesting the user use the Search tool to find Donald Trump's birthdate)\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mJune 14, 1946\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m```json\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"Donald Trump was born on June 14, 1946\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Bot: Donald Trump was born on June 14, 1946\n",
            "You: Get index of number 3 in this Python list: [22,3,4,5,7]\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_experimental.utilities.python:Python REPL can execute arbitrary code. Use with caution.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3m```json\n",
            "{\n",
            "    \"action\": \"Python_REPL\",\n",
            "    \"action_input\": \"print([i for i,x in enumerate([22,3,4,5,7]) if x == 3][0])\"\n",
            "}\n",
            "```\n",
            "\n",
            "This will execute the Python command and print the index of number 3 in the list.\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m1\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m```json\n",
            "{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": \"The index is 1.\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Bot: The index is 1.\n",
            "You: exit\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    query = input(\"You: \")\n",
        "    if query.lower() in [\"exit\", \"quit\"]:\n",
        "        break\n",
        "    response = agent.run(query)\n",
        "    print(\"Bot:\", response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rEmRfQlu0u9e"
      },
      "outputs": [],
      "source": [
        "pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "id": "VWUPYClx02DW",
        "outputId": "8045e673-a0cd-4ab3-8676-e405c4127c11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py:338: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a76c266739a22da7ec.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://a76c266739a22da7ec.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def chat_fn(message, history):\n",
        "    try:\n",
        "        response = agent.run(message)\n",
        "    except Exception as e:\n",
        "        response = f\"[ERROR] {str(e)}\"\n",
        "    return response\n",
        "\n",
        "iface = gr.ChatInterface(\n",
        "    fn=chat_fn,\n",
        "    title=\"LangChain RAG Chatbot\",\n",
        ")\n",
        "iface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nkduZxJ5n-3",
        "outputId": "d409ca8e-bdc4-45f6-842f-6e30563e58eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ],
      "source": [
        "# iface.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmVJkZALD-xb",
        "outputId": "bdd29438-7bde-4bf8-bb4a-0e72b91bb735"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[HumanMessage(content='what are langchain features', additional_kwargs={}, response_metadata={}), AIMessage(content='LangChain features include its ability to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.', additional_kwargs={}, response_metadata={}), HumanMessage(content='who is donald trump', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Donald Trump is an American businessman and politician who served as the 45th President of the United States from 2017 to 2021. He was born on June 14, 1946, in Queens, New York. Trump's presidency was marked by controversy and division, with many criticizing his policies and behavior.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='how old is he', additional_kwargs={}, response_metadata={}), AIMessage(content='Donald Trump was born on June 14, 1946', additional_kwargs={}, response_metadata={}), HumanMessage(content='Get index of number 3 in this Python list: [22,3,4,5,7]', additional_kwargs={}, response_metadata={}), AIMessage(content='The index is 1.', additional_kwargs={}, response_metadata={}), HumanMessage(content='who is joe biden', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Joe Biden is an American politician who served as the 46th Vice President of the United States from 2009 to 2017. He was a United States Senator from Delaware from 1973 to 2009 and a member of the House of Representatives from Delaware's at-large district from 1977 to 1983. Biden is a member of the Democratic Party.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='does he have children', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Joe Biden has four children: Beau Biden, Hunter Biden, Naomi 'Amy' Biden, and Ashley Biden.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='what are langchain features', additional_kwargs={}, response_metadata={}), AIMessage(content='LangChain features include its ability to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.', additional_kwargs={}, response_metadata={}), HumanMessage(content='what is 2^20 in python', additional_kwargs={}, response_metadata={}), AIMessage(content='The result is 1048576.', additional_kwargs={}, response_metadata={})]\n"
          ]
        }
      ],
      "source": [
        "print(memory.buffer)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 7355080,
          "sourceId": 11717145,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31011,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
